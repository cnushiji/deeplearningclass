import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

"""æ³¨æ„åŠ›ï¼ˆAttentionï¼‰æœºåˆ¶ç”±Bengioå›¢é˜Ÿäº2014å¹´æå‡ºå¹¶åœ¨è¿‘å¹´å¹¿æ³›çš„åº”ç”¨åœ¨æ·±åº¦å­¦ä¹ ä¸­çš„å„ä¸ªé¢†åŸŸï¼Œä¾‹å¦‚åœ¨è®¡ç®—æœºè§†è§‰æ–¹å‘ç”¨äºæ•æ‰å›¾åƒä¸Šçš„æ„Ÿå—é‡ï¼Œæˆ–è€…NLPä¸­ç”¨äºå®šä½å…³é”®tokenæˆ–è€…ç‰¹å¾ã€‚"""
"""é‡‡ç”¨Attentionæœºåˆ¶çš„åŸå› æ—¶è€ƒè™‘åˆ°RNNçš„è®¡ç®—é™åˆ¶æ˜¯é¡ºåºçš„ï¼Œä¹Ÿå°±æ˜¯è¯´RNNç›¸å…³ç®—æ³•æ™ºèƒ½ä»å·¦å‘å³ä¾æ¬¡è®¡ç®—æˆ–è€…ä»å³å‘å·¦ä¾æ¬¡è®¡ç®—ï¼Œè¿™ç§æœºåˆ¶å¸¦æ¥äº†ä¸¤ä¸ªé—®é¢˜ï¼š"""
r"""$ \qquad $ 1ï¼‰æ—¶é—´ç‰‡tçš„è®¡ç®—ä¾èµ–t-1æ—¶åˆ»çš„è®¡ç®—ç»“æœï¼Œè¿™æ ·é™åˆ¶äº†æ¨¡å‹çš„å¹¶è¡Œèƒ½åŠ›ï¼›"""
r"""$ \qquad $ 2ï¼‰é¡ºåºè®¡ç®—çš„è¿‡ç¨‹ä¸­ä¿¡æ¯ä¼šä¸¢å¤±ï¼Œå°½ç®¡LSTMç­‰é—¨æœºåˆ¶çš„ç»“æ„ä¸€å®šç¨‹åº¦ä¸Šç¼“è§£äº†é•¿æœŸä¾èµ–çš„é—®é¢˜ï¼Œä½†æ˜¯å¯¹äºç‰¹åˆ«é•¿æœŸçš„ä¾èµ–ç°è±¡ï¼ŒLSTMä¾æ—§æ— èƒ½ä¸ºåŠ›ã€‚"""
"""- Transformerçš„æå‡ºè§£å†³äº†ä¸Šé¢ä¸¤ä¸ªé—®é¢˜ï¼Œ"""
r"""$ \qquad $ 1ï¼‰é¦–å…ˆå®ƒä½¿ç”¨äº†Attentionæœºåˆ¶ï¼Œå°†åºåˆ—ä¸­çš„ä»»æ„ä¸¤ä¸ªä½ç½®ä¹‹é—´çš„è·ç¦»ç¼©å°ä¸ºä¸€ä¸ªå¸¸é‡ï¼›"""
r"""$ \qquad $ 2ï¼‰å…¶æ¬¡ï¼Œå®ƒä¸æ˜¯ç±»ä¼¼RNNçš„é¡ºåºç»“æ„ï¼Œå› æ­¤å…·æœ‰æ›´å¥½çš„å¹¶è¡Œæ€§ï¼Œç¬¦åˆç°æœ‰çš„GPUæ¡†æ¶ã€‚"""
"""- åœ¨æœºå™¨ç¿»è¯‘ä¸­ï¼ŒTransformerå¯æ¦‚æ‹¬ä¸ºå¦‚å›¾ï¼š"""
_, col1, _ = st.columns([1, 4, 1])
with col1:
    st.image('./pages/å›¾ç‰‡/å›¾ç‰‡22.png', caption='å›¾22')
"""- Transformeræœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªEncoder-Decoderçš„ç»“æ„ï¼Œé‚£ä¹ˆå›¾22å¯ä»¥è¡¨ç¤ºä¸ºå›¾23çš„ç»“æ„ï¼š"""
_, col1, _ = st.columns([1, 4, 1])
with col1:
    st.image('./pages/å›¾ç‰‡/å›¾ç‰‡23.png', caption='å›¾23')
"""- Transformerçš„Encoderå’ŒDecoderå‡ç”±6ä¸ªblockå †å è€Œæˆã€‚"""
col1, col2 = st.columns([1, 1])
with col1:
    st.image('./pages/å›¾ç‰‡/å›¾ç‰‡24.png', caption='å›¾24')
with col2:
    st.image('./pages/å›¾ç‰‡/å›¾ç‰‡25.png', caption='å›¾25')
st.latex(r"""Attention(Q,K,V)=softmax(\frac{QK^T}{\sqrt{d_k}})V""")
st.latex(r"""FFN(Z)=max(0,ZW_1+b_1)W_2+b_2""")
"""- è¾“å…¥ç¼–ç ï¼š"""
r"""$ \qquad $ é¦–å…ˆé€šè¿‡Word2Vecç­‰è¯åµŒå…¥æ–¹æ³•å°†è¾“å…¥è¯­æ–™è½¬åŒ–æˆç‰¹å¾å‘é‡ã€‚"""
_, col1, _ = st.columns([1, 4, 1])
with col1:
    st.image('./pages/å›¾ç‰‡/å›¾ç‰‡26.png', caption='å›¾26')
"""$ \qquad $ è¾“å…¥ç¼–ç ä½œä¸ºä¸€ä¸ªtensorè¾“å…¥åˆ°encoderä¸­"""
_, col1, _ = st.columns([1, 4, 1])
with col1:
    st.image('./pages/å›¾ç‰‡/å›¾ç‰‡27.png', caption='å›¾27')

"""- self-Attention:"""
r"""$ \qquad $ åœ¨self-attentionä¸­ï¼Œæ¯ä¸ªå•è¯ç”±3ä¸ªä¸åŒçš„å‘é‡ï¼Œåˆ†åˆ«æ˜¯Queryå‘é‡ï¼ˆQï¼‰,Keyå‘é‡(K)å’ŒValueå‘é‡(V),é•¿åº¦å‡æ˜¯64.å®ƒä»¬æ˜¯é€šè¿‡3ä¸ªä¸åŒçš„æƒå€¼çŸ©é˜µ$ğ‘Š^ğ‘„,ğ‘Š^ğ¾,ğ‘Š^ğ‘‰$å¾—åˆ°ï¼Œå…¶ä¸­ä¸‰ä¸ªçŸ©é˜µçš„å°ºå¯¸ä¹Ÿæ˜¯ç›¸åŒçš„ã€‚å‡æ˜¯512Ã—64ã€‚"""
_, col1, _ = st.columns([1, 4, 1])
with col1:
    st.image('./pages/å›¾ç‰‡/å›¾ç‰‡28.png', caption='å›¾28 Q,K,Vçš„è®¡ç®—ç¤ºä¾‹å›¾')
col1, col2 = st.columns([1, 1])
with col1:
    st.image('./pages/å›¾ç‰‡/å›¾ç‰‡29.png', caption='å›¾29 Self-Attentionè®¡ç®—ç¤ºä¾‹å›¾')
with col2:
    st.image('./pages/å›¾ç‰‡/å›¾ç‰‡30.png', caption='å›¾30 Q,K,Vçš„çŸ©é˜µè¡¨ç¤º')
_, col1, _ = st.columns([1, 4, 1])
with col1:
    st.image('./pages/å›¾ç‰‡/å›¾ç‰‡31.png', caption='å›¾31 Self-Attentionçš„çŸ©é˜µè¡¨ç¤º')
st.latex(r"""Attention(Q,K,V)=softmax(\frac{QK^T}{\sqrt{d_k}})V""")

"""- why self-Attention ?"""
r"""$ \qquad $ 1. computational complexity per layer"""
r"""$ \qquad $ 2. the amout of computation can be parallelized """
r"""$ \qquad $ 3. path length between long-range dependencies in the network"""
_, col1, _ = st.columns([1, 4, 1])
with col1:
    st.image('./pages/å›¾ç‰‡/å›¾ç‰‡32.png', caption='å›¾32')
"""- æ®‹å·®ç»“æ„:"""
r"""$ \qquad $ Self-attentionéœ€è¦å¼ºè°ƒçš„æœ€åä¸€ç‚¹æ˜¯å…¶é‡‡ç”¨äº†æ®‹å·®ç½‘ç»œä¸­çš„short-cutç»“æ„ï¼Œç›®çš„å½“ç„¶æ˜¯è§£å†³æ·±åº¦å­¦ä¹ ä¸­çš„é€€åŒ–é—®é¢˜ï¼Œå¾—åˆ°çš„æœ€ç»ˆçš„ç»“æœå¦‚å›¾ï¼š"""
_, col1, _ = st.columns([1, 4, 1])
with col1:
    st.image('./pages/å›¾ç‰‡/å›¾ç‰‡33.png', caption='å›¾33')
"""- Multi-Head Attention:"""
r"""$ \qquad $ Multi-Head Attentionç›¸å½“äºhä¸ªä¸åŒçš„self-attentionçš„é›†æˆï¼ˆensembleï¼‰å¦‚å›¾æ‰€ç¤ºï¼š"""
_, col1, _ = st.columns([1, 4, 1])
with col1:
    st.image('./pages/å›¾ç‰‡/å›¾ç‰‡34.png', caption='å›¾34')
"""- Encoder-Decoder Attention:"""
r"""$ \qquad $ åœ¨è§£ç å™¨ä¸­ï¼ŒTransformer blockæ¯”ç¼–ç å™¨ä¸­å¤šäº†ä¸ªencoder-decoder attentionã€‚åœ¨encoder-decoder attentionä¸­ï¼ŒQæ¥è‡ªäºè§£ç å™¨çš„ä¸Šä¸€ä¸ªè¾“å‡ºï¼ŒKå’ŒVåˆ™æ¥è‡ªäºç¼–ç å™¨çš„è¾“å‡ºã€‚"""
_, col1, _ = st.columns([1, 4, 1])
with col1:
    st.image('./pages/å›¾ç‰‡/å›¾ç‰‡35.png', caption='å›¾35')
"""- Transformer:"""
r"""$ \qquad $ ä¸€ä¸ªå®Œæ•´å¯è®­ç»ƒçš„ç½‘ç»œç»“æ„æ˜¯encoderå’Œdecoderçš„å †å ï¼ˆå„Nå„ï¼ŒN=6ï¼‰,å®Œæ•´çš„Transformerç»“æ„ï¼š"""
_, col1, _ = st.columns([1, 4, 1])
with col1:
    st.image('./pages/å›¾ç‰‡/å›¾ç‰‡36.png', caption='å›¾36')
"""- ä½ç½®ç¼–ç ï¼ˆPosition Embeddingï¼‰:"""
r"""$ \qquad $ ä½ç½®ç¼–ç ä¼šåœ¨è¯å‘é‡ä¸­åŠ å…¥äº†å•è¯çš„ä½ç½®ä¿¡æ¯ï¼Œè¿™æ ·Transformerå°±èƒ½åŒºåˆ†ä¸åŒä½ç½®çš„å•è¯ã€‚"""
r"""$ \qquad $ é€šå¸¸ä½ç½®ç¼–ç æ˜¯ä¸€ä¸ªé•¿åº¦ä¸ºğ‘‘_ğ‘šğ‘œğ‘‘ğ‘’ğ‘™çš„ç‰¹å¾å‘é‡ï¼Œè¿™æ ·ä¾¿äºå’Œè¯å‘é‡è¿›è¡Œå•ä½åŠ çš„æ“ä½œï¼Œå¦‚å›¾ï¼š"""
_, col1, _ = st.columns([1, 4, 1])
with col1:
    st.image('./pages/å›¾ç‰‡/å›¾ç‰‡37.png', caption='å›¾37')
"""- ä¼˜ç¼ºç‚¹ï¼š"""
r"""$ \qquad $ 1.ä¼˜ç‚¹ï¼š"""
r"""$ \qquad \qquad $ 1ï¼‰è®¾è®¡è¶³å¤Ÿåˆ›æ–°ï¼ŒæŠ›å¼ƒäº†åœ¨NLPä¸­æœ€æ ¹æœ¬çš„RNNæˆ–CNå¹¶å–å¾—äº†éå¸¸ä¸é”™çš„æ•ˆæœã€‚"""
r"""$ \qquad \qquad $ 2ï¼‰ä¸ä»…é™äºç”¨åœ¨NLPçš„æœºå™¨ç¿»è¯‘é¢†åŸŸã€‚"""
r"""$ \qquad $ 2. ç¼ºç‚¹ï¼š"""
r"""$ \qquad \qquad $ 1ï¼‰ç²—æš´çš„æŠ›å¼ƒRNNå’ŒCNNè™½ç„¶éå¸¸ç‚«æŠ€ï¼Œä½†æ˜¯å®ƒä¹Ÿä½¿æ¨¡å‹ä¸§å¤±äº†æ•æ‰å±€éƒ¨ç‰¹å¾çš„èƒ½åŠ›ï¼ŒRNN+CNN+Transformerçš„ç»“åˆå¯èƒ½ä¼šå¸¦æ¥æ›´å¥½çš„æ•ˆæœã€‚"""
r"""$ \qquad \qquad $ 2ï¼‰Transformerå¤±å»çš„ä½ç½®ä¿¡æ¯å…¶å®åœ¨NLPä¸­éå¸¸é‡è¦ï¼Œè®ºæ–‡ä¸­åœ¨ç‰¹å¾å‘é‡ä¸­åŠ å…¥äº†Position Embeddingä¹Ÿåªæ˜¯ä¸€ä¸ªæƒå®œä¹‹è®¡ï¼Œå¹¶æ²¡æœ‰æ”¹å˜Transformerç»“æ„ä¸Šçš„å›ºæœ‰ç¼ºé™·ã€‚"""
